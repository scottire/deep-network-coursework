{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "'''\n",
    "Created on 28 Aug 2018\n",
    "\n",
    "@author: marta\n",
    "'''\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "def read_data_set(filename):\n",
    "    df = pd.read_csv(filename, header = 0)\n",
    "    y = df.label.values\n",
    "    x = df.drop(['label'],axis=1).values\n",
    "    return x, y\n",
    "\n",
    "x, y = read_data_set('fashion-mnist_train.csv')\n",
    "x, y = shuffle(x, y, random_state=0)\n",
    "testX, testY = read_data_set('fashion-mnist_test.csv')\n",
    "x, y = shuffle(testX, testY, random_state=0)\n",
    "\n",
    "def toOneHot(y):\n",
    "    one_hot = np.zeros((len(y), np.amax(y)+1))\n",
    "    one_hot[np.arange(len(y)), y] = 1\n",
    "    return one_hot\n",
    "\n",
    "y = toOneHot(y)\n",
    "testY = toOneHot(testY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "i = random.randint(0, len(x))\n",
    "plt.imshow(x[i].reshape(28,28), cmap = matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(trainX, testX):\n",
    "    trainX = np.array(trainX, dtype=np.float64)\n",
    "    trainX -= np.mean(trainX) \n",
    "    trainX /= np.std(trainX, axis = 0)\n",
    "    \n",
    "    testX = np.array(testX, dtype=np.float64)\n",
    "    testX -= np.mean(trainX) ## Train centered around test mean\n",
    "    testX /= np.std(trainX, axis = 0)\n",
    "    return trainX, testX\n",
    "\n",
    "x, testX = preprocess(x, testX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 60000\n",
    "hidden_size = 2**7\n",
    "input_size = 28 * 28\n",
    "output_size = 10\n",
    "# print(x.shape)\n",
    "# sub_array_x = x[0:1000]\n",
    "# # print(sub_array.shape)\n",
    "\n",
    "# sub_array_y = y[0:1000]\n",
    "\n",
    "# w1 = np.random.uniform(-1,1,(HIDDEN_SIZE, sub_array_x.shape[1]))\n",
    "# # w1 = addBias(w1)\n",
    "# print(\"w1 shape\" + str(w1.shape))\n",
    "# b1 = np.full(sub_array_x.shape[1], 0.01)\n",
    "\n",
    "# # w2 = np.random.uniform(-1,1,(HIDDEN_SIZE, w1.shape[0]))\n",
    "# # print(\"w2 shape\" + str(w2.shape))\n",
    "\n",
    "# b2 = np.full(sub_array_x.shape[1], w1.shape[0])\n",
    "\n",
    "# # w2 = addBias(w2)\n",
    "\n",
    "# w2 = np.random.uniform(-1,1,(1, w1.shape[0]))\n",
    "# # b3 = np.full(sub_array.shape[1], w2.shape[0])\n",
    "# print(\"w2 shape\" + str(w2.shape))\n",
    "\n",
    "# # input_range = 1.0 / sub_array_x ** (1/2)\n",
    "# # output_range = 1.0 / HIDDEN_SIZE ** (1/2)\n",
    "# w1 = np.random.normal(loc = 0, size = (sub_array_x.shape[1], HIDDEN_SIZE))\n",
    "# w2 = np.random.normal(loc = 0, size = (w1.shape[0], 1))\n",
    "std=1e-4\n",
    "w1 = std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.ones(hidden_size)\n",
    "w2 = std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.ones(output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottcondron/anaconda3/envs/lab1/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class Activation:\n",
    "    \n",
    "    @staticmethod\n",
    "    def relu(x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        \"\"\" Use at output for multiclass problems for probabilities that sum to 1\n",
    "        \"\"\"\n",
    "        x -= np.max(x)\n",
    "        sm = (np.exp(x).T / np.sum(np.exp(x),axis=1)).T\n",
    "        return sm\n",
    "    \n",
    "class Loss:\n",
    "    @staticmethod\n",
    "    def crossEntropy(y, yhat):\n",
    "        \"\"\" Calculate Cost function\n",
    "            Reference: [4] \n",
    "        \"\"\"\n",
    "        m = y.shape[1]\n",
    "        return - 1./m * np.nansum(np.multiply(yhat, safeLog(y)) + np.multiply((1-yhat), safeLog(1-y)))\n",
    "    \n",
    "    \n",
    "def add_dropout(x):\n",
    "    \"\"\" Add dropout\n",
    "        Reference: [2] \n",
    "    \"\"\"\n",
    "    P = 0.9\n",
    "    dropoutMask = (np.random.rand(*x.shape) < P) / P \n",
    "    x = x * dropoutMask\n",
    "    return x\n",
    "\n",
    "def get_prediction(X, weights, biases):\n",
    "    weights_1 = weights[0]\n",
    "    weights_2 = weights[1]\n",
    "    bias_1 = biases[0]\n",
    "    bias_2 = biases[1]\n",
    "    h1 = Activation.relu(X.dot(weights_1) + bias_1)\n",
    "    y2 = h1.dot(weights_2) + bias_2\n",
    "    \n",
    "    y_pred = Activation.softmax(y2)\n",
    "    return y_pred\n",
    "\n",
    "def softmax(z):\n",
    "    z -= np.max(z)\n",
    "    sm = (np.exp(z).T / np.sum(np.exp(z),axis=1)).T\n",
    "    return sm\n",
    "\n",
    "def learningRateStepDecay(iteration, initialLearningRate=0.1, iterations_drop=10.0):\n",
    "    \"\"\" Reduce learning rate by half at intervals during training\n",
    "        Reference: [3] \n",
    "    \"\"\"\n",
    "    drop = 0.5\n",
    "    learningRate = initialLearningRate * math.pow(drop,  \n",
    "           math.floor((1+iteration)/iterations_drop))\n",
    "    learningRates.append(learningRate)\n",
    "    return learningRate\n",
    "\n",
    "def safeLog(x): \n",
    "    tiny=1e-12\n",
    "    x = np.clip(x, tiny, 1. - tiny)\n",
    "    return np.log(x)\n",
    "    \n",
    "costValues = []\n",
    "\n",
    "def calulate_gradients(X, y, weights, biases, dropout=True):\n",
    "    \"\"\" Calculate the change for the weights matrix\n",
    "        Reference: [1] \n",
    "    \"\"\"\n",
    "    \"\"\" Calculate predictions for given inputs and current weights\n",
    "        Reference: [1] \n",
    "    \"\"\"\n",
    "\n",
    "    W1, b1 = weights[0], biases[0]\n",
    "    W2, b2 = weights[1], biases[1]\n",
    "    N, D = X.shape\n",
    "\n",
    "    y1 = X.dot(W1) + b1 \n",
    "    h1 = Activation.relu(y1)\n",
    "    y2 = h1.dot(W2) + b2\n",
    "    scores = y2\n",
    "    \n",
    "    probs = Activation.softmax(scores) \n",
    "    dy2 = probs - y\n",
    "#     print(np.arange(N).shape)\n",
    "#     print(y.shape)\n",
    "#     print(dy2.shape)\n",
    "#     dy2[np.arange(N), y.astype(int)] -= 1\n",
    "#     delta = a[-1] - Y\n",
    "#     grads[-1] = a[-2].T.dot(delta)\n",
    "    \n",
    "    dy2 = probs - y\n",
    "    dy2 /= N\n",
    "\n",
    "    dW2 = h1.T.dot(dy2)\n",
    "    dh1 = dy2.dot(W2.T)\n",
    "    dy1 = dh1 * (y1 >= 0)\n",
    "    dW1 = X.T.dot(dy1)\n",
    "    db1 = np.sum(dy1, axis=0)\n",
    "    db2 = np.sum(dy2, axis=0)\n",
    "    if dropout==True:\n",
    "        dW1 = add_dropout(dW1)\n",
    "        dW2 = add_dropout(dW2)\n",
    "    grads = {}\n",
    "    grads['W1'] = dW1\n",
    "    grads['W2'] = dW2\n",
    "    grads['b1'] = db1\n",
    "    grads['b2'] = db2\n",
    "     \n",
    "    return grads\n",
    "\n",
    "def accuracy(yhat, y):\n",
    "#     print('yhat')\n",
    "#     print(yhat.shape)\n",
    "#     print('y')\n",
    "#     print(y.shape)\n",
    "    yhat_indices = np.argmax(yhat, axis=1)\n",
    "    y_indices = np.argmax(y, axis=1)\n",
    "    return accuracy_score(y_indices, yhat_indices)\n",
    "\n",
    "std=1e-4\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "cost = []\n",
    "ITERATIONS = 100\n",
    "\n",
    "#     w1 = std * np.random.randn(input_size, hidden_size)\n",
    "#     w2 = std * np.random.randn(hidden_size, output_size)\n",
    "\n",
    "w1 = np.random.randn(input_size, hidden_size) * np.sqrt(2.0 / input_size)\n",
    "b1 = np.ones(hidden_size)\n",
    "w2 = np.random.randn(hidden_size, output_size) * np.sqrt(2.0 / hidden_size)\n",
    "b2 = np.ones(output_size)\n",
    "\n",
    "#     print(\"x shape\")\n",
    "#     print(x.shape)\n",
    "#     print(\"w1 shape\")\n",
    "#     print(w1.shape)\n",
    "#     print(\"b1 shape\")\n",
    "#     print(b1.shape)\n",
    "#     print(\"w2 shape\")\n",
    "#     print(w2.shape)\n",
    "#     print(\"b2 shape\")\n",
    "#     print(b2.shape)\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    learning_rate = learningRateStepDecay(i, 0.001, ITERATIONS/10)\n",
    "#     learning_rate = 0.0001\n",
    "    gradients = calulate_gradients(x, y, weights=[w1, w2], biases=[b1, b2], dropout=False)\n",
    "    predicted_y_train = get_prediction(x, weights=[w1, w2], biases=[b1, b2])\n",
    "    cost.append(Loss.crossEntropy(y, predicted_y_train))    \n",
    "\n",
    "    train_acc = accuracy(predicted_y_train, y)\n",
    "    train_accs.append(train_acc)\n",
    "    predicted_y_test = get_prediction(testX, weights=[w1, w2], biases=[b1, b2])\n",
    "    val_acc = accuracy(predicted_y_test, testY)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    w1 += -learning_rate * gradients['W1']\n",
    "    w2 += -learning_rate * gradients['W2']\n",
    "    b1 += -learning_rate * gradients['b1']\n",
    "    b2 += -learning_rate * gradients['b2']  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accs)\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.xlabel('Iterations')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(val_accs)\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.xlabel('Iterations')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(cost)\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "predicted_y_test = get_prediction(testX,  weights=[w1, w2], biases=[b1, b2])\n",
    "i = random.randint(0,len(predicted_y_test))\n",
    "print(predicted_y_train[i].astype(int))\n",
    "print(y[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(train_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-462-f2081359ebdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearn_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-462-f2081359ebdc>\u001b[0m in \u001b[0;36mfeed_forward\u001b[0;34m(X, weights)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def feed_forward(X, weights):\n",
    "    a = [X]\n",
    "    for w in weights:\n",
    "        a.append(np.maximum(a[-1].dot(w),0))\n",
    "    return a\n",
    "\n",
    "def grads(X, Y, weights):\n",
    "    grads = np.empty_like(weights)\n",
    "    a = feed_forward(X, weights)\n",
    "    delta = a[-1] - Y\n",
    "    grads[-1] = a[-2].T.dot(delta)\n",
    "    for i in range(len(a)-2, 0, -1):\n",
    "        delta = (a[i] > 0) * delta.dot(weights[i].T)\n",
    "        grads[i-1] = a[i-1].T.dot(delta)\n",
    "    return grads / len(X)\n",
    "\n",
    "trX, trY, teX, teY = x, y, testX, testY\n",
    "weights = [np.random.randn(*w) * 0.1 for w in [(784, 100), (100, 10)]]\n",
    "num_epochs, batch_size, learn_rate = 30, 20, 0.1\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    for j in range(0, len(trX), batch_size):\n",
    "        X, Y = trX[j:j+batch_size], trY[j:j+batch_size]\n",
    "        weights -= learn_rate * grads(X, Y, weights)\n",
    "    prediction = np.argmax(feed_forward(teX, weights)[-1], axis=1)\n",
    "    print(np.mean(prediction == np.argmax(teY, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.20006273e-05  5.51227101e-05 -7.13671025e-05 ... -6.25317452e-05\n",
      "   7.34813266e-05 -6.98233164e-06]\n",
      " [-1.60606121e-04  1.45481656e-04  1.21157668e-08 ... -1.49475389e-04\n",
      "  -2.26472545e-05  4.85230347e-05]\n",
      " [ 7.40697189e-05 -3.03574552e-05  1.24732297e-05 ... -9.96223004e-05\n",
      "   1.05652796e-04  1.09940577e-04]\n",
      " ...\n",
      " [ 5.28749682e-06  1.87267118e-04 -6.99443848e-05 ... -1.21327609e-04\n",
      "  -2.81142500e-05  3.03499805e-05]\n",
      " [-2.59685694e-04  2.29576253e-05 -1.88557157e-06 ... -1.83677396e-05\n",
      "  -5.72328197e-05  1.00189172e-05]\n",
      " [-6.12490408e-05  8.36907408e-05  7.43009015e-05 ...  7.06306897e-06\n",
      "   5.75937617e-06 -3.14877505e-06]]\n"
     ]
    }
   ],
   "source": [
    "predicted_y_train = get_prediction(x, weights=[w1, w2], biases=[b1, b2])\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.05038611e-05  3.33230759e-05  1.05421261e-04 ... -1.21285472e-04\n",
      "   8.04238962e-05  1.77135813e-05]\n",
      " [ 2.19874047e-04  1.08808164e-04 -1.36731900e-04 ... -8.17413224e-05\n",
      "  -5.02157509e-05 -1.41387251e-04]\n",
      " [ 1.28948834e-04  3.14556474e-05 -8.55123425e-06 ... -2.14793246e-04\n",
      "  -1.00085555e-05 -9.41217300e-05]\n",
      " ...\n",
      " [-1.77511418e-04 -1.72446441e-04  1.80315455e-04 ... -6.49584907e-05\n",
      "   3.39001722e-05  1.39490750e-04]\n",
      " [ 2.77109686e-05 -1.04953626e-04  7.61662135e-05 ... -8.07443725e-05\n",
      "  -9.42005603e-05 -1.04670979e-04]\n",
      " [ 1.88806933e-04  5.46938034e-05  1.70116766e-06 ... -1.20646048e-04\n",
      "  -1.26735729e-04  4.31524548e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
